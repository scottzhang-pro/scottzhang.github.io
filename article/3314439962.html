<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png">
  <link rel="mask-icon" href="/images/logo.png" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic|Roboto Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"scottzhang.pro","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="我们学校比旁边的学校在教科书上面花了更多的钱吗？这是否有用呢？">
<meta property="og:type" content="article">
<meta property="og:title" content="监督学习实例：学校图书数据分类">
<meta property="og:url" content="https://scottzhang.pro/article/3314439962.html">
<meta property="og:site_name" content="Scott&#39;s Blog">
<meta property="og:description" content="我们学校比旁边的学校在教科书上面花了更多的钱吗？这是否有用呢？">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2019/11/18/SbPAWvxuiRELnO6.png">
<meta property="og:image" content="https://i.loli.net/2019/11/15/2cYvGT3VPQhU5dE.png">
<meta property="article:published_time" content="2019-08-17T16:02:27.000Z">
<meta property="article:modified_time" content="2021-11-27T08:20:09.816Z">
<meta property="article:author" content="Scott">
<meta property="article:tag" content="监督学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2019/11/18/SbPAWvxuiRELnO6.png">

<link rel="canonical" href="https://scottzhang.pro/article/3314439962.html">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>监督学习实例：学校图书数据分类 | Scott's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Scott's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Scott's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">学则不固, 知则不惑</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://scottzhang.pro/article/3314439962.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/instagram_profile_image.png">
      <meta itemprop="name" content="Scott">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Scott's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          监督学习实例：学校图书数据分类
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-18 00:02:27" itemprop="dateCreated datePublished" datetime="2019-08-18T00:02:27+08:00">2019-08-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-11-27 16:20:09" itemprop="dateModified" datetime="2021-11-27T16:20:09+08:00">2021-11-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/" itemprop="url" rel="index"><span itemprop="name">数据科学</span></a>
                </span>
            </span>

          
            <span id="/article/3314439962.html" class="post-meta-item leancloud_visitors" data-flag-title="监督学习实例：学校图书数据分类" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/article/3314439962.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/article/3314439962.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
<p><img src="https://i.loli.net/2019/11/18/SbPAWvxuiRELnO6.png" /></p>
<blockquote>
<p>我们学校比旁边的学校在教科书上面花了更多的钱吗？这是否有用呢？</p>
</blockquote>
<span id="more"></span>
<h1 id="问题">问题</h1>
<p>学校想知道，我们比旁边的学校在教科书上面花了更多的钱吗？这是否有用？</p>
<p>要回答这个问题，首先我们需要有教科书的数据，并进行分类。然而分类是一个及其复杂的操作，学校每年都会花很多的时间去手动分类。</p>
<p>我们的目标是可以建立一个机器学习模型自动处理这个分类步骤。</p>
<p>比如《线性代数》，这本书我们会给他几个标签：</p>
<ul>
<li>数学</li>
<li>教科书</li>
<li>中学</li>
</ul>
<p>这些标签，就是我们的target variable。</p>
<p>这是一个典型的分类问题。</p>
<p>不过我们的预测应该由概率来定义，我们不会预测说，这就是本数学书，而是说,我有百分之60的把握认为这是一本数学书，如果不对，那我有百分之70的把握认为这是一本物理书。</p>
<h1 id="导入数据">导入数据</h1>
<p>数据是csv格式的，我们使用<code>df = pd.read_csv('TrainingData.csv')</code>导入数据并保存到名为<code>df</code>的变量。</p>
<h2 id="探索数据">探索数据</h2>
<p><strong>基本信息</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">In [6]: df.info()</span><br><span class="line">&lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;</span><br><span class="line">RangeIndex: 1560 entries, 0 to 1559</span><br><span class="line">Data columns (total 26 columns):</span><br><span class="line">Unnamed: 0                1560 non-null int64</span><br><span class="line">Function                  1560 non-null object</span><br><span class="line">Use                       1560 non-null object</span><br><span class="line">Sharing                   1560 non-null object</span><br><span class="line">Reporting                 1560 non-null object</span><br><span class="line">Student_Type              1560 non-null object</span><br><span class="line">Position_Type             1560 non-null object</span><br><span class="line">Object_Type               1560 non-null object</span><br><span class="line">Pre_K                     1560 non-null object</span><br><span class="line">Operating_Status          1560 non-null object</span><br><span class="line">Object_Description        1461 non-null object</span><br><span class="line">Text_2                    382 non-null object</span><br><span class="line">SubFund_Description       1183 non-null object</span><br><span class="line">Job_Title_Description     1131 non-null object</span><br><span class="line">Text_3                    677 non-null object</span><br><span class="line">Text_4                    193 non-null object</span><br><span class="line">Sub_Object_Description    364 non-null object</span><br><span class="line">Location_Description      874 non-null object</span><br><span class="line">FTE                       449 non-null float64</span><br><span class="line">Function_Description      1340 non-null object</span><br><span class="line">Facility_or_Department    252 non-null object</span><br><span class="line">Position_Extra            1026 non-null object</span><br><span class="line">Total                     1542 non-null float64</span><br><span class="line">Program_Description       1192 non-null object</span><br><span class="line">Fund_Description          819 non-null object</span><br><span class="line">Text_1                    1132 non-null object</span><br><span class="line">dtypes: float64(2), int64(1), object(23)</span><br><span class="line">memory usage: 317.0+ KB</span><br></pre></td></tr></table></figure>
<p><strong>简单描述:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">In [5]: df.describe()</span><br><span class="line">Out[5]:</span><br><span class="line">          Unnamed: 0         FTE         Total</span><br><span class="line">count    1560.000000  449.000000  1.542000e+03</span><br><span class="line">mean   227767.180128    0.493532  1.446867e+04</span><br><span class="line">std    130207.535688    0.452844  7.916752e+04</span><br><span class="line">min       198.000000   -0.002369 -1.044084e+06</span><br><span class="line">25%    113690.750000         NaN           NaN</span><br><span class="line">50%    226445.500000         NaN           NaN</span><br><span class="line">75%    340883.500000         NaN           NaN</span><br><span class="line">max    450277.000000    1.047222  1.367500e+06</span><br></pre></td></tr></table></figure>
<h2 id="fte-全职员工数">FTE 全职员工数</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [4]: df.FTE.head()</span><br><span class="line">Out[4]:</span><br><span class="line">198     NaN</span><br><span class="line">209     NaN</span><br><span class="line">750     1.0</span><br><span class="line">931     NaN</span><br><span class="line">1524    NaN</span><br><span class="line">Name: FTE, dtype: float64</span><br></pre></td></tr></table></figure>
<p>数据里的FTE为(Full Time equivalent)全职员工的意思,在我们的数据中，如果一项预算与一个员工有关，这个值就反应了这个员工的全职工作的百分比。</p>
<ul>
<li>1，全职员工</li>
<li>0，兼职或者合同制员工</li>
</ul>
<p>这个值本身是有许多的数据缺失的，所以如果要使用的话，需要先将na值去掉。</p>
<p>将FTE绘图，可以看到，这所学校的兼职员工和全职员工的支出很高，而中间的数据则比较少。</p>
<p><img src="https://i.loli.net/2019/11/15/2cYvGT3VPQhU5dE.png" /></p>
<h2 id="数据类型">数据类型</h2>
<p>我们的数据中，有些列只有特定的值，比如:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df.label.unique()</span><br><span class="line"></span><br><span class="line">[&#x27;a&#x27;,&#x27;b&#x27;]</span><br></pre></td></tr></table></figure>
<p>我们需要将其变成数字来处理，一是我们的模型只能计算数字，而是可以提升速度。</p>
<p>在pandas中，有一种 <code>category</code> 类型的数据，可以干这件事。</p>
<p>通过pandas的 <code>astype()</code>方法，可以将一列数据转化成 <code>category</code>，转化后，就可以使用 <code>get_dummies方法</code>来查看 dummy variables,这会让原来的每个值都用数字来替代,如：</p>
<p><em>原始数据：</em></p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">origin</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: left;">US</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: left;">Europe</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2</td>
<td style="text-align: left;">Asia</td>
</tr>
</tbody>
</table>
<p><em>get_dummies()后：</em></p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">origin_Asia</th>
<th style="text-align: left;">origin_Europe</th>
<th style="text-align: left;">origin_US</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">0</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
</tr>
</tbody>
</table>
<p>这个步骤又叫做 <code>binary indicator</code> representation.</p>
<p>如果你有多列数据需要转化成 <code>category</code>类型，可以使用 lambda 函数加dataframe的apply方法，记得设置axis=0，也就是处理方式是按列，处理完成之后，你可以使用<code>df.dtypes.value_counts()</code>来查看你的数据里数据类型的分布情况。</p>
<h1 id="如何定义成功">如何定义成功？</h1>
<p>用accuracy，没办法解决垃圾邮件的问题，这个我们在机器学习那一章已经讲过，所以我们使用<code>log loss</code>，简单来说,accuracy是尽可能的提高正确率，而<code>log loss</code>则是尽可能的降低错误率。</p>
<p>下面是我们使用的<code>loss function</code>的定义：</p>
<p><span class="math display">\[logloss=-\frac{1}{N}\sum_{i=1}^{N}(y_ilogs(p_i))+(1-y_i)log(1-p_i)\]</span></p>
<ul>
<li>y：是否分类正确，1=yes,0=no</li>
<li>p：为1的概率</li>
</ul>
<p>复习一下，</p>
<p><span class="math display">\[\sum\]</span></p>
<p>叫做求和符号，读作<em>segema</em>,它的意思就是连续的加法，比如:</p>
<p><span class="math display">\[\sum_{k=1}^{n}ak=a_1+a_2+a_3+..a_n\]</span></p>
<p>k是下标，它会从k变化到n，当k=1的时候，ak就是a1，当k=2的时候，ak就是a2，最后一项就是k=n,segima的意思呢就是把这些项全都加起来。</p>
<p>所以这里的segema的意思就是把数据中，每一行的数据都加起来，如果你不了解求和符号，可以参考我的这篇<a target="_blank" rel="noopener" href="http://wittyfans.com/math/%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%EF%BC%9A%E6%B1%82%E5%92%8C%E7%AC%A6%E5%8F%B7.html">文章</a></p>
<p>把一行的数据乘以 <span class="math display">\[-\frac{1}{N}\]</span>，得到这一行的logloss.</p>
<h2 id="log-loss函数示例">log loss函数示例</h2>
<h3 id="假设a">假设A</h3>
<ul>
<li>true label=0</li>
<li>预测1的概率是p=0.9：</li>
</ul>
<p>带入公式计算可得：</p>
<p><span class="math display">\[log loss=(1-y)\log^{1-p}\]</span></p>
<p><span class="math display">\[=\log^{1-0.9}\]</span></p>
<p><span class="math display">\[=\log^{0.1}\]</span></p>
<p><span class="math display">\[=2.3\]</span></p>
<h3 id="假设b">假设B</h3>
<ul>
<li>true label=1</li>
<li>预测0的概率是0.5</li>
</ul>
<p>则los函数表示为：</p>
<p><span class="math display">\[logloss=-\frac{1}{1}1\log^{0.5}+(1-1)\log^{1-0.5}\]</span></p>
<p>带入公式计算可得：</p>
<p><span class="math display">\[=-\log^{0.5}\]</span></p>
<p><span class="math display">\[=0.69\]</span></p>
<h3 id="log-loss-python实现">log loss python实现</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def compute_log_loss(predicted, actual, eps=1e-14):</span><br><span class="line"> &quot;&quot;&quot; Computes the logarithmic loss between predicted and</span><br><span class="line"> actual when these are 1D arrays.</span><br><span class="line"></span><br><span class="line"> :param predicted: The predicted probabilities as floats between 0-1</span><br><span class="line"> :param actual: The actual binary labels. Either 0 or 1.</span><br><span class="line"> :param eps (optional): log(0) is inf, so we need to offset our</span><br><span class="line"> predicted values slightly by eps from 0 or 1.</span><br><span class="line"> &quot;&quot;&quot;</span><br><span class="line"> predicted = np.clip(predicted, eps, 1 - eps)</span><br><span class="line"> loss = -1 * np.mean(actual * np.log(predicted)</span><br><span class="line"> + (1 - actual)</span><br><span class="line"> * np.log(1 - predicted))</span><br><span class="line"></span><br><span class="line"> return loss</span><br></pre></td></tr></table></figure>
<p>我们可以用这个函数取计算一些提供好的值的log loss值，下面是算好后的结果:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Log loss, correct and confident: 0.05129329438755058</span><br><span class="line">Log loss, correct and not confident: 0.4307829160924542</span><br><span class="line">Log loss, wrong and not confident: 1.049822124498678</span><br><span class="line">Log loss, wrong and confident: 2.9957322735539904</span><br><span class="line">Log loss, actual labels: 9.99200722162646e-15</span><br></pre></td></tr></table></figure>
<p>可以看到，模型的预测越准确，则logloss值越低，真实值的logloss是极低的。</p>
<h1 id="建立模型">建立模型</h1>
<p>我们建模往往都是一开始建立简单的模型，然后再慢慢的优化。</p>
<p>所以快速的建立模型，很有必要，我们从 <em>mutil-class logistic regression</em> 开始，简单的模型我们就只选择数字类型的了，其他的列都不要，然后将列分开建模，然后把整个数据按行拿进来预测，观察在这一列是否有出现。</p>
<p>但还有一个问题，在之前的课程中，我们将数据分割成train组与test组，但这个方案在这里是不行的，而且那中情况只适合单个 target 的情况。</p>
<p>这里我们会使用另外一个函数来分割数据，叫做 <em>mutil_label_train_test_split</em></p>
<p>随后我们找出所有数字类型的features作为trains set, 把我们感兴趣的 lebels 也拿出来（以get_dummies的形式），就可以利用这两组数据生成train与test数据了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># Create the new DataFrame: numeric_data_only</span><br><span class="line">numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000)</span><br><span class="line"></span><br><span class="line"># Get labels and convert to dummy variables: label_dummies</span><br><span class="line">label_dummies = pd.get_dummies(df[LABELS])</span><br><span class="line"></span><br><span class="line"># Create training and test sets</span><br><span class="line">X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,label_dummies,size=0.2,seed=123)</span><br><span class="line"></span><br><span class="line"># Print the info</span><br><span class="line">print(&quot;X_train info:&quot;)</span><br><span class="line">print(X_train.info())</span><br><span class="line">print(&quot;\nX_test info:&quot;)  </span><br><span class="line">print(X_test.info())</span><br><span class="line">print(&quot;\ny_train info:&quot;)  </span><br><span class="line">print(y_train.info())</span><br><span class="line">print(&quot;\ny_test info:&quot;)  </span><br><span class="line">print(y_test.info())</span><br></pre></td></tr></table></figure>
<p>有了traning数据之后，就可以训练模型并计算我们的模型得分了，这里为了将我们的列分开计算，我们需要使用 <em>‌OneVsRestClassifier</em> 包，用法如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># Import classifiers</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.multiclass import OneVsRestClassifier</span><br><span class="line"></span><br><span class="line"># Create the DataFrame: numeric_data_only</span><br><span class="line">numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000)</span><br><span class="line"></span><br><span class="line"># Get labels and convert to dummy variables: label_dummies</span><br><span class="line">label_dummies = pd.get_dummies(df[LABELS])</span><br><span class="line"></span><br><span class="line"># Create training and test sets</span><br><span class="line">X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,label_dummies,size=0.2, seed=123)</span><br><span class="line"></span><br><span class="line"># Instantiate the classifier: clf</span><br><span class="line">clf = OneVsRestClassifier(LogisticRegression())</span><br><span class="line"></span><br><span class="line"># Fit the classifier to the training data</span><br><span class="line">clf.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line"># Print the accuracy</span><br><span class="line">print(&quot;Accuracy: &#123;&#125;&quot;.format(clf.score(X_test,y_test)))</span><br></pre></td></tr></table></figure>
<h2 id="预测">预测</h2>
<p>这一次我们利用真实的数据来预测，这些数据是模型从未见过的，我们通过pd.read_csv导入它</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># Instantiate the classifier: clf</span><br><span class="line">clf = OneVsRestClassifier(LogisticRegression())</span><br><span class="line"></span><br><span class="line"># Fit it to the training data</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"># Load the holdout data: holdout</span><br><span class="line">holdout = pd.read_csv(&quot;HoldoutData.csv&quot;,index_col=0)</span><br><span class="line"></span><br><span class="line"># Generate predictions: predictions</span><br><span class="line">predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS].fillna(-1000))</span><br></pre></td></tr></table></figure>
<h2 id="自然语言处理简要概述nlp">自然语言处理简要概述（NLP）</h2>
<h3 id="tokenizing-与-gram">Tokenizing 与 gram</h3>
<p>Tokenizing即将文本变成词语，简单的直接按照空格或者是标点符号分割，复杂一点会有自此识别，如结巴分词中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我来到北京清华大学</span><br></pre></td></tr></table></figure>
<p>变成：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学</span><br></pre></td></tr></table></figure>
<p>在上面的例子中，gram的选择会有不一样的效果,如果gram=1，则结果变成:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我/ 来/到/ 北/京/ 清/华/ 大/学</span><br></pre></td></tr></table></figure>
<p>如果gram=2,则： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我来/到北/京清/华大/学</span><br></pre></td></tr></table></figure></p>
<h2 id="文本到数字">文本到数字</h2>
<p>上面的语句变成词语组，这些词语就叫做 <code>bag of words</code></p>
<p>在 sklearn中，有一个方法可以计算bag of words，<em>CountVectorizer</em>。</p>
<p>使用之前，你需要给CountVectorizer传入一个正则表达式，它才知道如何去分割字词，对了，不要忘记处理你数据中的missing value.</p>
<p>当你用正则创建好CountVectorizer后，就可以把语句传进来计算bag of words,一样它也是使用fit方法。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># Import CountVectorizer</span><br><span class="line">from sklearn.feature_extraction.text import CountVectorizer</span><br><span class="line"></span><br><span class="line"># Create the token pattern: TOKENS_ALPHANUMERIC</span><br><span class="line">TOKENS_ALPHANUMERIC = &#x27;[A-Za-z0-9]+(?=\\s+)&#x27;</span><br><span class="line"></span><br><span class="line"># Fill missing values in df.Position_Extra</span><br><span class="line">df.Position_Extra.fillna(&#x27;&#x27;,inplace=True)</span><br><span class="line"></span><br><span class="line"># Instantiate the CountVectorizer: vec_alphanumeric</span><br><span class="line">vec_alphanumeric = CountVectorizer(token_pattern=&#x27;[A-Za-z0-9]+(?=\s+)&#x27;)</span><br><span class="line"></span><br><span class="line"># Fit to the data</span><br><span class="line">vec_alphanumeric.fit(df.Position_Extra)</span><br><span class="line"></span><br><span class="line"># Print the number of tokens and first 15 tokens</span><br><span class="line">msg = &quot;There are &#123;&#125; tokens in Position_Extra if we split on non-alpha numeric&quot;</span><br><span class="line">print(msg.format(len(vec_alphanumeric.get_feature_names())))</span><br><span class="line">print(vec_alphanumeric.get_feature_names()[:15])</span><br></pre></td></tr></table></figure>
<h1 id="改善您的模型">改善您的模型</h1>
<h2 id="pipelines-feature-text-preprocessing">Pipelines, feature &amp; text preprocessing</h2>
<p>我们已经接触过pipline了，它可以让我们处理数据的步骤变得更容易。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># Import Pipeline</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line"># Import other necessary modules</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.multiclass import OneVsRestClassifier</span><br><span class="line"></span><br><span class="line"># Split and select numeric data only, no nans</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(sample_df[[&#x27;numeric&#x27;]],pd.get_dummies(sample_df[&#x27;label&#x27;]),random_state=22)</span><br><span class="line"></span><br><span class="line"># Instantiate Pipeline object: pl</span><br><span class="line">pl = Pipeline([</span><br><span class="line">    (&#x27;clf&#x27;, OneVsRestClassifier(LogisticRegression()))</span><br><span class="line">])</span><br><span class="line"># Fit the pipeline to the training data</span><br><span class="line">pl.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"># Compute and print accuracyaccuracy = pl.score(X_test, y_test)</span><br><span class="line">print(&quot;\nAccuracy on sample data - numeric, no nans: &quot;, accuracy)</span><br></pre></td></tr></table></figure>
<p>对于pipline，它是按照顺序来执行里面的步骤的，所以您需要规划好顺序，例如对于你的数据，如果有缺失值，你必须在训练模型之前就将这些na值处理好:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pl = Pipeline([</span><br><span class="line">        (&#x27;imp&#x27;, Imputer()),</span><br><span class="line">        (&#x27;clf&#x27;, OneVsRestClassifier(LogisticRegression()))</span><br><span class="line">    ])</span><br></pre></td></tr></table></figure>
<p>这里使用了inputer来处理缺失值。</p>
<p>pipline对象的使用一样也是调用fit方法，并且pipline对象还提供了打分的功能(默认是accuracy)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Fit the pipeline to the training data</span><br><span class="line">pl.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line"># Compute and print accuracy</span><br><span class="line">accuracy = pl.score(X_test,y_test)</span><br></pre></td></tr></table></figure>
<h2 id="text-features-and-feature-unions">Text features and feature unions</h2>
<p>对于我们的text值，不可以把它和数值型的数据一起处理，即不可以放在同一个pipline中。</p>
<p>怎么办呢？解决方案是使用Function Transformer()和FeatureUnion()</p>
<p>Function Transformer()做的事情很简单，就是接受一个python函数，把它转化成sklearn可以理解的对象，然后用它去处理数据。</p>
<p>我们可以写两个函数，都接受所有的dataframe，但是一个输出text的处理结果，另一个输出数值型数据的结果。</p>
<p>这样我们就可以对数值型数据与text型数据分别设置两套pipline。</p>
<p>在 Function Transformer() 参数重，我们将参数 validate设置为false，以让其不检查空值。</p>
<p>FeatureUnion是另一个我们需要用到的包，当我们用function transformer的时候，一个是数值型数据，另一个是文本型数据，FeatureUnion可以把这两个features联合到一起作为同一个数组，作为classifier的输入。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># Import FeatureUnion</span><br><span class="line">from sklearn.pipeline import FeatureUnion</span><br><span class="line"></span><br><span class="line"># Split using ALL data in sample_df</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(sample_df[[&#x27;numeric&#x27;, &#x27;with_missing&#x27;, &#x27;text&#x27;]],pd.get_dummies(sample_df[&#x27;label&#x27;]), random_state=22)</span><br><span class="line"></span><br><span class="line"># Create a FeatureUnion with nested pipeline: process_and_join_features</span><br><span class="line">process_and_join_features = FeatureUnion(</span><br><span class="line">            transformer_list = [</span><br><span class="line">                (&#x27;numeric_features&#x27;, Pipeline([</span><br><span class="line">                    (&#x27;selector&#x27;, get_numeric_data),</span><br><span class="line">                    (&#x27;imputer&#x27;, Imputer())</span><br><span class="line">                ])),</span><br><span class="line">                (&#x27;text_features&#x27;, Pipeline([</span><br><span class="line">                    (&#x27;selector&#x27;, get_text_data),</span><br><span class="line">                    (&#x27;vectorizer&#x27;, CountVectorizer())</span><br><span class="line">                ]))</span><br><span class="line">             ]</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"># Instantiate nested pipeline: pl</span><br><span class="line">pl = Pipeline([</span><br><span class="line">        (&#x27;union&#x27;, process_and_join_features),</span><br><span class="line">        (&#x27;clf&#x27;, OneVsRestClassifier(LogisticRegression()))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Fit pl to the training data</span><br><span class="line">pl.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"># Compute and print accuracy</span><br><span class="line">accuracy = pl.score(X_test, y_test)</span><br><span class="line">print(&quot;\nAccuracy on sample data - all data: &quot;, accuracy)</span><br></pre></td></tr></table></figure>
<h2 id="回归学校数据">回归学校数据</h2>
<p>对于之前的问题，我们的数据中只有一列是文本型数据，而学校数据中，则有14列。</p>
<p>我们需要将这些列都结合起来，这个函数已经写好了，叫做 <code>combine_text_columns</code>, 定义好之后，只需要在定义Function Transformer()的时候更改一下参数就好了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># Import FunctionTransformer</span><br><span class="line">from sklearn.preprocessing import FunctionTransformer</span><br><span class="line"></span><br><span class="line"># Get the dummy encoding of the labels</span><br><span class="line">dummy_labels = pd.get_dummies(df[LABELS])</span><br><span class="line"></span><br><span class="line"># Get the columns that are features in the original df</span><br><span class="line">NON_LABELS = [c for c in df.columns if c not in LABELS]</span><br><span class="line"></span><br><span class="line"># Split into training and test sets</span><br><span class="line">X_train, X_test, y_train, y_test = multilabel_train_test_split(df[NON_LABELS],dummy_labels,0.2, seed=123)</span><br><span class="line"></span><br><span class="line"># Preprocess the text data: get_text_data</span><br><span class="line">get_text_data = FunctionTransformer(combine_text_columns,validate=False)</span><br><span class="line"></span><br><span class="line"># Preprocess the numeric data: get_numeric_data</span><br><span class="line">get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)</span><br></pre></td></tr></table></figure>
<p>定义好处理文本和数字的函数之后，我们就可以建立模型了：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># Complete the pipeline: pl</span><br><span class="line">pl = Pipeline([</span><br><span class="line">        (&#x27;union&#x27;, FeatureUnion(</span><br><span class="line">            transformer_list = [</span><br><span class="line">                (&#x27;numeric_features&#x27;, Pipeline([</span><br><span class="line">                    (&#x27;selector&#x27;, get_numeric_data),</span><br><span class="line">                    (&#x27;imputer&#x27;, Imputer())</span><br><span class="line">                ])),</span><br><span class="line">                (&#x27;text_features&#x27;, Pipeline([</span><br><span class="line">                    (&#x27;selector&#x27;, get_text_data),</span><br><span class="line">                    (&#x27;vectorizer&#x27;, CountVectorizer())</span><br><span class="line">                ]))</span><br><span class="line">             ]</span><br><span class="line">        )),</span><br><span class="line">        (&#x27;clf&#x27;, OneVsRestClassifier(LogisticRegression()))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line"># Fit to the training data</span><br><span class="line">pl.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line"># Compute and print accuracy</span><br><span class="line">accuracy = pl.score(X_test, y_test)</span><br><span class="line">print(&quot;\nAccuracy on budget dataset: &quot;, accuracy)</span><br></pre></td></tr></table></figure>
<p>可以看到pipline输出的分数。这个处理的步骤是不是很熟悉，这个步骤是通用的，而且如果你想要更换别的分类器，只需要将 <code>LogisticRegression</code> 改成别的就好了，例如在这个例子里，你把模型改成<em>RandomForestClassifier</em>，将会有0.2的提升，如果把<em>RandomForestClassifier</em>的参数<em>n_estimators</em>改成15，<em>accuracy</em> 还有有所增加。</p>
<h1 id="专家指点">专家指点</h1>
<ul>
<li>tokenize text，不仅仅只是根据空格与标点来处理文字</li>
<li>n-gram statistics，文字的选择我们定义gram，我们也可以同时定义多个gram，如,<code>CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,ngram_range=(1,2)))</code></li>
<li>使用预知的alpha-numeric sequences,对于text，只接受字母数字序列</li>
</ul>
<h2 id="统计技巧interaction-terms">统计技巧,interaction terms</h2>
<p>来看一组例子,这两组数据中，English teacher和2nd grade 都有出现</p>
<ul>
<li><em>English teacher for 2nd grade</em></li>
<li><em>2nd grade - budget for English teacher</em></li>
</ul>
<p><span class="math display">\[\beta_1x_1+\beta_2x_2+\beta_3(x_1x_2)\]</span></p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">x_1</th>
<th style="text-align: left;">x_2</th>
<th style="text-align: left;">x3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">x1*x2=0*1=0</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">x1*x2=1*1=1</td>
</tr>
</tbody>
</table>
<ul>
<li>x1,x2代表某个特定的token有出现</li>
<li>beta符号则代表其重要程度或者说相关系数</li>
<li>x3是x1、x2两者的乘积</li>
</ul>
<p>当然，sklearn提供了一种非常直接的方式使用interaction terms，即：<em>PolynomialFeatures</em>,</p>
<p>另外还有一个叫做SparseInteractions的包，也可以做同样的事情。</p>
<p>最后，我们不可能因为选一个不一样的模型就改善所有的情况，模型的优化是一个渐进的步骤，可能是你将模型的某个参数调整一下，可能是你在语义处理方面更换了一个更好的工具，这些东西都需要你去根据你的实际情况作出调整。</p>
<p>这篇文章就到这里结束了，下一篇将会是非监督学习。</p>

    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/uploads/wechat-reward-image.png" alt="Scott 微信支付">
        <p>微信支付</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" rel="tag"># 监督学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/article/1659388510.html" rel="prev" title="Scikit-Learn 与监督学习">
      <i class="fa fa-chevron-left"></i> Scikit-Learn 与监督学习
    </a></div>
      <div class="post-nav-item">
    <a href="/article/2329768004.html" rel="next" title="机器学习：处理Jira工单的分类问题">
      机器学习：处理Jira工单的分类问题 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%97%AE%E9%A2%98"><span class="nav-number">1.</span> <span class="nav-text">问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="nav-number">2.</span> <span class="nav-text">导入数据</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8E%A2%E7%B4%A2%E6%95%B0%E6%8D%AE"><span class="nav-number">2.1.</span> <span class="nav-text">探索数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#fte-%E5%85%A8%E8%81%8C%E5%91%98%E5%B7%A5%E6%95%B0"><span class="nav-number">2.2.</span> <span class="nav-text">FTE 全职员工数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="nav-number">2.3.</span> <span class="nav-text">数据类型</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E5%AE%9A%E4%B9%89%E6%88%90%E5%8A%9F"><span class="nav-number">3.</span> <span class="nav-text">如何定义成功？</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#log-loss%E5%87%BD%E6%95%B0%E7%A4%BA%E4%BE%8B"><span class="nav-number">3.1.</span> <span class="nav-text">log loss函数示例</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%81%87%E8%AE%BEa"><span class="nav-number">3.1.1.</span> <span class="nav-text">假设A</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%81%87%E8%AE%BEb"><span class="nav-number">3.1.2.</span> <span class="nav-text">假设B</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#log-loss-python%E5%AE%9E%E7%8E%B0"><span class="nav-number">3.1.3.</span> <span class="nav-text">log loss python实现</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%BB%BA%E7%AB%8B%E6%A8%A1%E5%9E%8B"><span class="nav-number">4.</span> <span class="nav-text">建立模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%A2%84%E6%B5%8B"><span class="nav-number">4.1.</span> <span class="nav-text">预测</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AE%80%E8%A6%81%E6%A6%82%E8%BF%B0nlp"><span class="nav-number">4.2.</span> <span class="nav-text">自然语言处理简要概述（NLP）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#tokenizing-%E4%B8%8E-gram"><span class="nav-number">4.2.1.</span> <span class="nav-text">Tokenizing 与 gram</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%87%E6%9C%AC%E5%88%B0%E6%95%B0%E5%AD%97"><span class="nav-number">4.3.</span> <span class="nav-text">文本到数字</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%94%B9%E5%96%84%E6%82%A8%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.</span> <span class="nav-text">改善您的模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#pipelines-feature-text-preprocessing"><span class="nav-number">5.1.</span> <span class="nav-text">Pipelines, feature &amp; text preprocessing</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#text-features-and-feature-unions"><span class="nav-number">5.2.</span> <span class="nav-text">Text features and feature unions</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%9E%E5%BD%92%E5%AD%A6%E6%A0%A1%E6%95%B0%E6%8D%AE"><span class="nav-number">5.3.</span> <span class="nav-text">回归学校数据</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%93%E5%AE%B6%E6%8C%87%E7%82%B9"><span class="nav-number">6.</span> <span class="nav-text">专家指点</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%9F%E8%AE%A1%E6%8A%80%E5%B7%A7interaction-terms"><span class="nav-number">6.1.</span> <span class="nav-text">统计技巧,interaction terms</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Scott"
      src="/uploads/instagram_profile_image.png">
  <p class="site-author-name" itemprop="name">Scott</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">69</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">75</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/wittyfans" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;wittyfans" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/wittyfans" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;wittyfans" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/wittyfans0" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;wittyfans0" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Scott</span>
</div>

        






<script>
  (function() {
    function leancloudSelector(url) {
      url = encodeURI(url);
      return document.getElementById(url).querySelector('.leancloud-visitors-count');
    }

    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.id);
      var title = visitors.dataset.flagTitle;

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url })))
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            leancloudSelector(url).innerText = counter.time + 1;
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .catch(error => {
                console.error('Failed to save visitor count', error);
              });
          } else {
              Counter('post', '/classes/Counter', { title, url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.error('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.id);
      });

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url: { '$in': entries } })))
        .then(response => response.json())
        .then(({ results }) => {
          for (let url of entries) {
            let target = results.find(item => item.url === url);
            leancloudSelector(url).innerText = target ? target.time : 0;
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    let { app_id, app_key, server_url } = {"enable":true,"app_id":"7sScl0n1AlEtVDaUHuXzxPqc-gzGzoHsz","app_key":"qKXpoqGbK1sdFYMiik7Evuan","server_url":"https://7sscl0n1.lc-cn-n1-shared.com","security":false};
    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${api_server}/1.1${url}`, {
          method,
          headers: {
            'X-LC-Id'     : app_id,
            'X-LC-Key'    : app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    }

    let api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${app_id.slice(0, 8).toLowerCase()}.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(response => response.json())
        .then(({ api_server }) => {
          fetchData('https://' + api_server);
        });
    }
  })();
</script>


      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>

<script src="/js/utils.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '7sScl0n1AlEtVDaUHuXzxPqc-gzGzoHsz',
      appKey     : 'qKXpoqGbK1sdFYMiik7Evuan',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
